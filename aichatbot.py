# -*- coding: utf-8 -*-
"""AIChatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y5ebrLjcgRqyZ5Hc83hwPDrOOulvegp7
"""

!pip install -q PyPDF2 sentence-transformers chromadb google-generativeai

import os
import io
import json
import zipfile
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
import chromadb
import google.generativeai as genai

# Embedding model
EMBED_MODEL = SentenceTransformer("all-MiniLM-L6-v2")

# ChromaDB persistent client
CHROMA_CLIENT = chromadb.PersistentClient(path="docs_db")
COLLECTION = CHROMA_CLIENT.get_or_create_collection(name="doc_chunks")

# Gemini API key (replace with your key or use Colab secret)
GEN_API_KEY = "AIzaSyAPteCJMtCZBCP4QJbfmfksFk3yEoG1Dt0"
genai.configure(api_key=GEN_API_KEY)
GEMINI_MODEL = genai.GenerativeModel("gemini-2.5-flash")

def parse_pdf(file_path: str, chunks: list, file_id: str):
    reader = PdfReader(file_path)
    for i, page in enumerate(reader.pages):
        text = page.extract_text()
        if not text:
            continue
        chunk = {
            "chunkId": f"{file_id}_page_{i+1}",
            "pageNumbers": [i + 1],
            "fileName": os.path.basename(file_path),
            "text": text.strip(),
        }
        chunks.append(chunk)

def parse_folder(folder_path: str, json_out="parsed_pdfs.json"):
    chunks = []
    for file_name in os.listdir(folder_path):
        if file_name.lower().endswith(".pdf"):
            file_path = os.path.join(folder_path, file_name)
            file_id = os.path.splitext(file_name)[0]
            parse_pdf(file_path, chunks, file_id)
    data = {"chunks": chunks}
    with open(json_out, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    return json_out

def store_in_vector_db(json_path="parsed_pdfs.json"):
    try:
        COLLECTION.delete(where={"page": {"$gte": 0}})
    except:
        pass

    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    texts, ids, metadatas = [], [], []
    for i, chunk in enumerate(data.get("chunks", [])):
        text = chunk.get("text", "")
        if not text.strip():
            continue
        ids.append(chunk.get("chunkId", f"chunk_{i}"))
        metadatas.append({
            "page": chunk.get("pageNumbers", [None])[0],
            "file": chunk.get("fileName", "unknown")
        })
        texts.append(text)

    embeddings = EMBED_MODEL.encode(texts, show_progress_bar=True).tolist()
    COLLECTION.add(ids=ids, documents=texts, embeddings=embeddings, metadatas=metadatas)
    return len(texts)

def retrieve(query: str, n_results=5):
    embedding = EMBED_MODEL.encode(query).tolist()
    results = COLLECTION.query(query_embeddings=[embedding], n_results=n_results)
    return results

def generate_answer(query: str, results):
    documents = results.get("documents", [[]])
    metadatas = results.get("metadatas", [[]])
    if not documents or not documents[0]:
        return "No relevant context found."

    context_texts = []
    for doc, meta in zip(documents[0], metadatas[0]):
        context_texts.append(f"{doc}\n(File: {meta.get('file')}, Page: {meta.get('page')})")

    context = "\n\n".join(context_texts)
    prompt = f"""
You are a documentation assistant.
Use the following context to answer the question.

Context:
{context}

Question:
{query}

Answer clearly and concisely.
"""
    try:
        response = GEMINI_MODEL.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"‚ùå LLM Error: {str(e)}"

from google.colab import files
import os

# Create folder for uploaded PDFs
os.makedirs("uploaded_pdfs", exist_ok=True)

print("üìÇ Upload one or more PDFs (hold Ctrl/Cmd to select multiple)")

# Upload files
uploaded = files.upload()

# Save all uploaded PDFs
pdf_files = []
for filename in uploaded.keys():
    if filename.lower().endswith(".pdf"):
        path = os.path.join("uploaded_pdfs", filename)
        with open(path, "wb") as f:
            f.write(uploaded[filename])
        pdf_files.append(filename)
        print(f"‚úÖ Saved: {filename}")

if not pdf_files:
    print("‚ùå No PDFs were uploaded.")
else:
    print(f"üìÑ PDFs ready for processing: {pdf_files}")

# Parse PDFs and store in vector DB
json_file = parse_folder("uploaded_pdfs")
count = store_in_vector_db(json_file)
print(f"‚úÖ Stored {count} chunks from uploaded PDFs.")

query = "Summarize all uploaded documents."
results = retrieve(query, n_results=8)
print("\nü§ñ Answer:\n", generate_answer(query, results))

while True:
    query = input("‚ùì Ask a question (or type 'exit'): ")
    if query.lower() in ["exit", "quit"]:
        break
    results = retrieve(query, n_results=8)
    print("\nü§ñ Answer:\n", generate_answer(query, results), "\n")